---
title: "Статистический анализ категориальных признаков и проверка гипотез однородности"
author: "Вейбер Е.Н. 23.М08-мм"
date: "23-04-2024"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Введение

Это отчет о статистическом анализе категориальных признаков и проверке гипотез однородности. Вариант 18.

## Выполнение тестов хи-квадрат и критерия Фишера для данных addicts.csv
```{r}
# Загрузка необходимых библиотек
library(tidyverse)
library(ggplot2)
library(readr)
library(corrplot)
library(tidyr)
library(GGally)
library(plotly)
library(stats)
library(reshape2)

#Просмотр данных
data <- read_delim("~/Downloads/addicts.csv", delim = ";")
head(data)
summary(data)

# Функция для выполнения тестов хи-квадрат и критерия Фишера и печати результатов
perform_tests <- function(data, indep_var) {
  # Создаем таблицу сопряженности для зависимой переменной и независимой переменной
  contingency_table <- table(data[[indep_var]], data$end)
  
  # Критерий хи-квадрат
  chi_test <- chisq.test(contingency_table)
  
  # Точный критерий Фишера, используется, если какие-либо ожидаемые частоты < 5
  if(any(chi_test$expected < 5)) {
    fisher_test <- fisher.test(contingency_table)
    fisher_p_value <- fisher_test$p.value
  } else {
    fisher_p_value <- NA
  }
  
  # Вычисляем условные вероятности
  prop_table <- prop.table(contingency_table, margin = 1)
  
  # Печатаем результаты
  cat("\nКритерий хи-квадрат для", indep_var, ":\n")
  print(chi_test)
  
  if(!is.na(fisher_p_value)) {
    cat("\nТочный критерий Фишера для", indep_var, ":\n")
    print(fisher_p_value)
  }
  
  cat("\nУсловные вероятности для", indep_var, ":\n")
  print(prop_table)
  
  # Значимости отличия
  cat("\nP-значения:\n")
  cat("Хи-квадрат: ", chi_test$p.value, "\n")
  if(!is.na(fisher_p_value)) {
    cat("Фишера: ", fisher_p_value, "\n")
  }
}

# Выполнение тестов для каждой переменной
perform_tests(data, "curwor")
perform_tests(data, "st")
perform_tests(data, "se")
```
### Анализ результатов тестов независимости для переменной **curwor** выявил следующее:

1. **Критерий Хи-квадрат Пирсона**:
   - Статистика \(X^2 = 3.6667\) с 2 степенями свободы.
   - \(p\)-значение равно 0.1599, что указывает на отсутствие статистически значимых доказательств для отклонения нулевой гипотезы о независимости переменной **curwor** от зависимой переменной. То есть, по результатам этого теста, изменения в **curwor** могут не оказывать значимого влияния на исследуемый результат.

2. **Точный тест Фишера**:
   - \(p\)-значение равно 0.1150461, что также выше обычного порога значимости (например, 0.05), подтверждая выводы критерия Хи-квадрат о возможной независимости между переменными.

3. **Условные вероятности для curwor**:
   - Для категории **curwor = 0**, условные вероятности перехода в состояние `0` составляют 75%, а в состояние `1` — 24.5%.
   - Для категории **curwor = 1**, условные вероятности перехода в состояние `0` составляют 64.5%, а в состояние `1` — 35.6%.

Исходя из полученных данных, можно заключить, что влияние переменной **curwor** на исследуемый результат не является статистически значимым.  
### Анализ результатов тестов независимости для переменной **st** показывает следующее:

1. **Критерий Хи-квадрат Пирсона**:
   - Статистика \(X^2 = 5.8892\) с 4 степенями свободы.
   - \(p\)-значение составляет 0.2076, что указывает на отсутствие статистически значимых доказательств против нулевой гипотезы о независимости переменной **st** от зависимой переменной. Это говорит о том, что изменения в **st** возможно не влияют на результаты в значимой степени.

2. **Точный тест Фишера**:
   - \(p\)-значение равно 0.1035544, что также свидетельствует о незначительном статистическом влиянии переменной **st** на исходные данные, подтверждая результаты Хи-квадрат теста.

3. **Условные вероятности для st**:
   - Для категории, где **st** не определено (NULL), вероятность перехода в состояние `1` составляет 100%.
   - Для категории **st = 0**, условные вероятности перехода в состояние `0` составляют 70.6%, а в состояние `1` — 29.0%.
   - Для категории **st = 1**, условные вероятности перехода в состояние `0` составляют 85.3%, а в состояние `1` — 14.7%.

Эти результаты предполагают, что фактор **st** не оказывает значимого статистического воздействия на рассматриваемые исходы.
### Анализ результатов тестов независимости для переменной **se** дает следующую картину:

1. **Критерий Хи-квадрат Пирсона**:
   - Статистика \(X^2 = 8.7823\) с 4 степенями свободы.
   - \(p\)-значение составляет 0.06678, что приближается к обычному порогу значимости 0.05. Это означает, что есть некоторое предположение о влиянии переменной **se** на исход, но это влияние не достигает статистической значимости при традиционном уровне 0.05.

2. **Точный тест Фишера**:
   - \(p\)-значение равно 0.03207796, что меньше уровня значимости 0.05. Это указывает на наличие статистически значимых различий в условных распределениях зависимости от переменной **se**.

3. **Условные вероятности для se**:
   - Для категории, где **se** не определено (NULL), вероятность перехода в состояние `1` составляет 100%.
   - Для категории **se = 0**, условные вероятности перехода в состояние `0` составляют 69.95%, а в состояние `1` — 29.58%.
   - Для категории **se = 1**, условные вероятности перехода в состояние `0` составляют 81.54%, а в состояние `1` — 18.46%.

**Выводы**:
- Результаты точного теста Фишера указывают на наличие значимого влияния переменной **se** на результаты, в то время как Хи-квадрат тест не находит такого же четкого подтверждения.
- Различия в условных вероятностях между разными категориями **se** подтверждают возможное влияние этой переменной на исходные данные.

## Вычисление  коэффициентов неопределенности для зависимой переменной end и для каждой из независимых  категориальных переменных curwor, se, st.
```{r}
# Загрузка необходимых библиотек
library(vcd)  # Для коэффициента V Крамера

# Функция для расчета коэффициента неопределенности между двумя переменными
calc_uncertainty_coefficient <- function(data, var1, var2) {
  # Создание таблицы сопряженности
  contingency_table <- table(data[[var1]], data[[var2]])
  
  # Вычисление теста хи-квадрат
  chi_sq_test <- chisq.test(contingency_table)
  
  # Вычисление V Крамера
  cramers_v <- sqrt(chi_sq_test$statistic / (nrow(data) * (min(dim(contingency_table)) - 1)))
  
  return(cramers_v)
}

# Вычисление коэффициента неопределенности для каждой независимой переменной
cramers_v_curwor <- calc_uncertainty_coefficient(data, "end", "curwor")
cramers_v_se <- calc_uncertainty_coefficient(data, "end", "se")
cramers_v_st <- calc_uncertainty_coefficient(data, "end", "st")

# Вывод результатов
cat("Коэффициент V Крамера для end и curwor:", cramers_v_curwor, "\n")
cat("Коэффициент V Крамера для end и se:", cramers_v_se, "\n")
cat("Коэффициент V Крамера для end и st:", cramers_v_st, "\n")

# Функция для расчета коэффициентов неопределенности для списка переменных
calc_uncertainty_coefficients <- function(data, dependent_var, independent_vars) {
  sapply(independent_vars, function(independent_var) {
    contingency_table <- table(data[[dependent_var]], data[[independent_var]])
    chi_sq_test <- chisq.test(contingency_table)
    cramers_v <- sqrt(chi_sq_test$statistic / (nrow(data) * (min(dim(contingency_table)) - 1)))
    cramers_v
  })
}

# Список независимых переменных
independent_vars <- c("curwor", "se", "st")

# Вычисление коэффициентов Крамера
cramers_v_values <- calc_uncertainty_coefficients(data, "end", independent_vars)

# Названия для вывода результатов
names(cramers_v_values) <- independent_vars

# Вывод результатов
print(cramers_v_values)

summary(data)
```
Коэффициенты V Крамера, полученные для переменных **curwor**, **se** и **st** относительно зависимой переменной **end**, указывают на степень ассоциации между этими категориальными переменными и исходом **end**. Вот что означают полученные значения:

1. **Коэффициент V Крамера для end и curwor: 0.1144342**
   - Это значение указывает на слабую связь между переменными **curwor** и **end**. Низкое значение коэффициента Крамера подразумевает, что вариабельность исхода **end** слабо обусловлена значениями переменной **curwor**.

2. **Коэффициент V Крамера для end и se: 0.1252306**
   - Показатель немного выше, чем для **curwor**, но все еще остается в пределах слабой связи. Это подразумевает, что хотя переменная **se** имеет некоторое влияние на **end**, это влияние не является существенным.

3. **Коэффициент V Крамера для end и st: 0.1025493**
   - Это значение еще меньше, чем у двух предыдущих переменных, и подчеркивает очень слабую связь между **st** и **end**.

**Общий вывод**:
Все три переменные демонстрируют только слабую ассоциацию с зависимой переменной **end**. Это означает, что другие факторы, не включенные в анализ, могут играть большую роль в объяснении вариативности исхода **end**. Для более полного понимания влияния этих переменных на исход **end** может потребоваться более глубокий анализ.

## Проверка гипотезы о равенстве дисперсий двух выборок, проверка значимости критерия Фишера и применение критерия Стьюдента для проверки равенства средних для группирующей переменной factor.2:
```{r}
data$se <- as.factor(data$se)

# Получение уникальных значений для признака se, исключая NA
unique_se_values <- unique(data$se[!is.na(data$se)])

# Список для хранения данных по группам и дисперсий
grouped_se <- list()
grouped_variance_se <- numeric(length(unique_se_values))

# Преобразование asi4_dr к числовому типу
# Замена запятых на точки в строках
data$asi4_dr <- gsub(",", ".", data$asi4_dr)

# Преобразование в числовой тип
data$asi4_dr <- as.numeric(data$asi4_dr)
head(data)
# Удаление NA из списка уникальных значений se
unique_se_values <- na.omit(unique(data$se))

# Цикл по всем уникальным значениям, исключая NA
for (i in seq_along(unique_se_values)) {
  value <- unique_se_values[i]
  
  # Выборка данных по текущему значению se, исключая строки с NA в asi4_dr
  group_data <- data[data$se == value & !is.na(data$asi4_dr), "asi4_dr", drop = FALSE]
  
  # Вычисление дисперсии для текущей группы, учитывая NA значения
  grouped_variance_se[i] <- var(group_data$asi4_dr, na.rm = TRUE)
  
  # Сохранение данных по группе в список
  grouped_se[[as.character(value)]] <- group_data
  
  # Вывод дисперсии для текущей группы
  cat(sprintf("Дисперсия для группы %s = %.5f\n", value, grouped_variance_se[i]))
}
# Проверка равенства дисперсий и средних для первых двух доступных групп
if (length(grouped_se) >= 2) {
  # Критерий Фишера для проверки равенства дисперсий
  f_test_result <- var.test(grouped_se[[1]]$asi4_dr, grouped_se[[2]]$asi4_dr)
  cat(sprintf("P-значение критерия Фишера для групп %s и %s: %.5f\n",
              names(grouped_se)[1], names(grouped_se)[2], f_test_result$p.value))
  
  # Критерий Стьюдента для проверки равенства средних
  t_test_result <- t.test(grouped_se[[1]]$asi4_dr, grouped_se[[2]]$asi4_dr, 
                          var.equal = f_test_result$p.value > 0.05)
  cat(sprintf("P-значение критерия Стьюдента для групп %s и %s: %.5f\n",
              names(grouped_se)[1], names(grouped_se)[2], t_test_result$p.value))
}
```
Дисперсия для группы 0 и группы 1 указывает на то, как сильно значения переменной в каждой группе отклоняются от среднего значения этой группы. В контексте статистического анализа, дисперсия является мерой разброса данных.

- **Дисперсия для группы 0 составляет 0.00309.** Это значение показывает, что данные в этой группе имеют относительно небольшой разброс вокруг среднего значения, что может указывать на более однородную группу по изучаемой переменной.

- **Дисперсия для группы 1 равна 0.00585.** Эта дисперсия выше, чем у группы 0, что говорит о том, что данные в этой группе более разнообразны и менее однородны по сравнению с группой 0.
Ваш код корректно выполнил проверку гипотез о равенстве дисперсий и средних для двух групп данных. Вот интерпретация полученных результатов:

1. **Критерий Фишера (Тест Фишера на равенство дисперсий)**:
   - **P-значение: 0.00077**. Это значение меньше стандартного уровня значимости 0.05, что указывает на статистически значимые различия в дисперсиях между группами 0 и 1. Можно заключить, что дисперсии в этих двух группах не равны.

2. **Критерий Стьюдента (t-тест на равенство средних)**:
   - При выполнении t-теста на равенство средних, была принята предпосылка о неравенстве дисперсий (поскольку p-значение критерия Фишера меньше 0.05).
   - **P-значение: 0.24782**. Это значение больше 0.05, что говорит о том, что нет статистически значимых различий в средних значениях между группами 0 и 1. Следовательно, несмотря на различие в дисперсиях, средние значения между этими группами не показывают значимого отличия на уровне 0.05.

Таким образом, хотя дисперсии между группами различаются, средние значения не показывают статистически значимых различий. Это может указывать на то, что различия в дисперсиях не обязательно приводят к различиям в средних значениях или на то, что влияние других факторов (например, размер выборки или особенности распределения данных) могут влиять на результаты t-теста.

### Применение однофакторного дисперсионного анализа в случае фактора с четырьмя градациями и множественных сравнений с разными поправками. Применение критерия Ливиня и Бартлетта для првоерки равенства дисперсий:
```{r}
# Загрузка необходимых библиотек
library(car)   # для теста Ливиня
library(stats) # для ANOVA и теста Бартлетта
library(multcomp) # для множественных сравнений

# Переменная ответа asi4_dr и группирующая переменная educat находятся в датафрейме data
# Преобразование educat в фактор
data$educat <- as.factor(data$educat)

# Проверка гипотезы о равенстве дисперсий
# Тест Ливиня
levene_test <- leveneTest(data$asi4_dr, data$educat, center = median)
print(levene_test)

# Тест Бартлетта
bartlett_test <- bartlett.test(data$asi4_dr, data$educat)
print(bartlett_test)

# Однофакторный дисперсионный анализ
anova_result <- aov(asi4_dr ~ educat, data = data)
summary(anova_result)

# Множественные сравнения
# Используем поправки: Тьюки, Бонферрони, Холма
tukey_test <- TukeyHSD(anova_result)
print(tukey_test)

# Множественные сравнения с поправкой Бонферрони
bonferroni_test <- glht(anova_result, linfct = mcp(educat = "Tukey"))
summary(bonferroni_test, test = adjusted("bonferroni"))

# Множественные сравнения с поправкой Холма
holm_test <- glht(anova_result, linfct = mcp(educat = "Tukey"))
summary(holm_test, test = adjusted("holm"))
```
Различие в результатах тестов Ливиня и Бартлетта на одних и тех же данных интересно и требует дополнительного анализа и понимания характеристик данных и условий применимости каждого теста.  

1. **Тест Ливиня**: Этот тест менее чувствителен к отклонениям от нормальности распределения, поскольку использует медианы или средние значения в качестве центральной тенденции для расчета вариаций в группах. Показатель F-значение 0.319 и p-значение 0.8116 говорят о том, что нет статистически значимых различий в дисперсиях между группами. Это означает, что с точки зрения теста Ливиня дисперсии между группами можно считать однородными.

2. **Тест Бартлетта**: Этот тест более чувствителен к нарушениям нормальности распределения данных. Показатель Bartlett's K-squared 21.051 и p-значение 0.0001027 указывают на то, что дисперсии между группами статистически значимо различаются. Это может быть результатом того, что данные не соответствуют нормальному распределению, что делает тест Бартлетта более подверженным к выводу о наличии различий даже там, где их может не быть.  

### Результаты однофакторного дисперсионного анализа (ANOVA), проведённого на датасете, показывают следующее:

1. **Df (Degrees of Freedom, степени свободы)**:
   - **educat**: 3 — указывает на количество групп, минус один (4 группы - 1).
   - **Residuals**: 276 — остаточные степени свободы, равные общему числу наблюдений минус количество групп (количество наблюдений - 4).

2. **Sum Sq (Sum of Squares, сумма квадратов)**:
   - **educat**: 0.0088 — сумма квадратов между группами, показывает вариабельность данных, объяснённую переменной educat.
   - **Residuals**: 1.0283 — сумма квадратов внутри групп, показывает остаточную вариабельность, которую не объясняет переменная educat.

3. **Mean Sq (Mean Squares, средние квадраты)**:
   - **educat**: 0.002943 — средний квадрат между группами, получается делением суммы квадратов между группами на соответствующие степени свободы.
   - **Residuals**: 0.003726 — средний квадрат внутри групп.

4. **F value (F-значение)**: 
   - 0.79 — статистика, используемая для определения статистической значимости различий между средними значениями разных групп. Она показывает отношение среднего квадрата между группами к среднему квадрату внутри групп.

5. **Pr(>F) (p-value, p-значение)**:
   - 0.5 — вероятность получить такое или более экстремальное значение F-статистики, если нулевая гипотеза о том, что все групповые средние равны, верна.

### Интерпретация результатов:

- **F value** относительно низкое, и **p-value** равное 0.5 свидетельствует о том, что нет статистически значимых различий между средними значениями переменной asi4_dr для различных категорий educat. Это означает, что изменения в educat не влияют на значения asi4_dr в данной выборке.
- Высокое p-value говорит о том, что мы не отвергаем нулевую гипотезу о равенстве средних, что указывает на то, что переменная educat не оказывает значимого влияния на asi4_dr.

### Результаты теста Тьюки показывают множественные сравнения средних значений переменной `asi4_dr` между различными уровнями категориальной переменной `educat`. Этот тест используется после выполнения однофакторного дисперсионного анализа (ANOVA), чтобы уточнить, между какими группами существуют статистически значимые различия.

Выводы из результатов теста Тьюки:

- **diff**: Разница между средними значениями групп.
- **lwr**: Нижняя граница 95% доверительного интервала для разницы между средними.
- **upr**: Верхняя граница 95% доверительного интервала.
- **p adj**: P-значение, скорректированное на множественные сравнения.

### Результаты сравнений:
1. **2-1**:
   - Разница между группами 2 и 1 составляет приблизительно 0.0049.
   - P-значение 0.985 указывает на отсутствие статистически значимого различия между этими группами.
   
2. **3-1**:
   - Разница между группами 3 и 1 равна 0.0202.
   - P-значение 0.660 также не свидетельствует о значимых различиях между группами 3 и 1.

3. **4-1**:
   - Разница между группами 4 и 1 составляет -0.0095, что указывает на незначительное уменьшение в группе 4 по сравнению с группой 1.
   - P-значение 0.980 подтверждает отсутствие статистической значимости этого различия.

4. **3-2**, **4-2**, **4-3**:
   - Сравнения этих групп также показывают различия в средних, но все соответствующие P-значения (0.593, 0.899, 0.581) указывают на то, что эти различия не являются статистически значимыми.

### Общий вывод:
Тест Тьюки не выявил значимых различий между средними значениями переменной `asi4_dr` для различных уровней переменной `educat`. Это согласуется с результатами ANOVA, которые также не показали значимых различий в воздействии разных уровней образования на `asi4_dr`. Это может указывать на то, что переменная `educat` не имеет значительного влияния на изучаемую метрику в данной выборке.

### Результаты теста Bonferroni, полученные из множественного сравнения средств с помощью глобального критерия Tukey для контрастов, демонстрируют сравнения между различными уровнями переменной `educat` в отношении зависимой переменной `asi4_dr`.

### Параметры сравнения:
- **Estimate**: Разница между средними значениями групп.
- **Std. Error**: Стандартная ошибка разницы средних.
- **t value**: Значение t-статистики для данного сравнения.
- **Pr(>|t|)**: P-значение для теста, скорректированное методом Bonferroni для контроля общей ошибки I рода при множественных сравнениях.

### Результаты теста:
- **2 - 1**: Разница средних между группой 2 и группой 1 составляет 0.004891, что не является статистически значимым (p-значение скорректировано до 1).
- **3 - 1**: Разница между группами 3 и 1 равна 0.020238, что также не демонстрирует статистической значимости (p-значение 1).
- **4 - 1**: Разница между группами 4 и 1 составляет -0.009524, без статистической значимости (p-значение 1).
- **3 - 2**: Разница между группами 3 и 2 равна 0.015347, без статистической значимости (p-значение 1).
- **4 - 2**: Разница между группами 4 и 2 составляет -0.014414, без статистической значимости (p-значение 1).
- **4 - 3**: Разница между группами 4 и 3 составляет -0.029762, также без статистической значимости (p-значение 1).

### Общий вывод:
Тест Bonferroni не выявил статистически значимых различий между любыми из рассматриваемых групп. Это подтверждает выводы предыдущих анализов (ANOVA и Tukey HSD), которые также указывали на отсутствие значимого влияния уровня образования (`educat`) на переменную `asi4_dr`. Все скорректированные p-значения значительно превышают обычный пороговый уровень (0.05), что указывает на то, что любые наблюдаемые различия между группами можно считать случайными.

### Результаты множественных сравнений средних с использованием теста Holm (поправка Holm) демонстрируют следующее:

### Результаты:
- **Estimate**: Это разница средних между соответствующими группами.
- **Std. Error**: Стандартная ошибка этой разницы.
- **t value**: Значение t-статистики для данного сравнения.
- **Pr(>|t|)**: P-значение для каждого теста, скорректированное по методу Holm.

### Сравнения:
1. **Группа 2 против Группы 1** (2 - 1 == 0): Средняя разница составляет 0.004891. Статистически значимых различий не найдено (скорректированное p-значение = 1).
2. **Группа 3 против Группы 1** (3 - 1 == 0): Средняя разница составляет 0.020238. Статистически значимых различий не найдено (скорректированное p-значение = 1).
3. **Группа 4 против Группы 1** (4 - 1 == 0): Средняя разница составляет -0.009524. Статистически значимых различий не найдено (скорректированное p-значение = 1).
4. **Группа 3 против Группы 2** (3 - 2 == 0): Средняя разница составляет 0.015347. Статистически значимых различий не найдено (скорректированное p-значение = 1).
5. **Группа 4 против Группы 2** (4 - 2 == 0): Средняя разница составляет -0.014414. Статистически значимых различий не найдено (скорректированное p-значение = 1).
6. **Группа 4 против Группы 3** (4 - 3 == 0): Средняя разница составляет -0.029762. Статистически значимых различий не найдено (скорректированное p-значение = 1).

### Вывод:
Метод Holm не обнаружил статистически значимых различий между сравниваемыми группами. Это указывает на то, что, несмотря на наблюдаемые различия в средних значениях, они не достигают статистической значимости после коррекции для множественного тестирования. Этот результат согласуется с выводами других методов множественных сравнений, представленных в предыдущих анализах.

## Выполнение критерия Вилкоксона для сравнения двух выборок:
```{r}
# Фильтрация данных для двух выбранных групп по переменной educat
group1_data <- data[data$educat == 1, "asi4_dr", drop = FALSE]
group2_data <- data[data$educat == 2, "asi4_dr", drop = FALSE]
vector_gr_1 <- c(group1_data)
vector_gr_2 <- c(group2_data)

wilcox_test <- wilcox.test(vector_gr_1$asi4_dr, vector_gr_2$asi4_dr, alternative = "two.sided")

# Вывод результатов теста
print(wilcox_test)
```
Результаты теста Wilcoxon rank sum показывают следующее:

1. Значение статистики W составляет 2222.5.
2. P-значение равно 0.6626.
3. Альтернативная гипотеза указывает на то, что истинное смещение местоположения не равно 0.

Интерпретация:
- Поскольку p-значение (0.6626) больше общепринятого уровня значимости (например, 0.05), нет статистически значимых доказательств против нулевой гипотезы о равенстве местоположения в двух группах.
- Таким образом, на основании этого теста нет оснований отвергать нулевую гипотезу о том, что средние значения в двух группах одинаковы.

## Поиск медианы для первых двух зависимых переменных и преобразование признаков в дихотомические в зависимости от положения относительно медианы:
```{r}
data <- read_delim("~/Desktop/dataNF.csv", delim = ";")
head(data)

library(ez)

# Преобразование данных
data$SEX.1 <- as.factor(data$SEX.1)
data$PRCOD.1 <- as.factor(data$PRCOD.1)
# Замена NA средними значениями по каждому столбцу
features <- c("BDI.1", "BDI.4", "BDI.5", "BDI.7")
data <- data %>%
  mutate(across(all_of(features), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))

# Устанавливаем новые имена для колонок
names(data) <- gsub("BDI\\.", "BDI_", names(data))
names(data) <- gsub("PRCOD\\.", "PRCOD_", names(data))
names(data) <- gsub("SEX\\.", "SEX_", names(data))

# Находим медиану для переменной BDI_1
med1 <- median(data$BDI_1, na.rm = TRUE)

# Преобразование переменных BDI.1 и BDI.4 в дихотомические по медиане med1
data$BDI_1.binary <- ifelse(data$BDI_1 > med1, 1, 0)
data$BDI_4.binary <- ifelse(data$BDI_4 > med1, 1, 0)

# Создание гистограммы для BDI.1.binary
ggplot(data, aes(x = factor(BDI_1.binary))) +
  geom_bar(fill = "blue", alpha = 0.7) +
  labs(title = "Гистограмма BDI_1 по медиане", x = "BDI_1 (Больше медианы = 1)", y = "Количество") +
  theme_minimal()

# Создание гистограммы для BDI_4.binary
ggplot(data, aes(x = factor(BDI_4.binary))) +
  geom_bar(fill = "red", alpha = 0.7) +
  labs(title = "Гистограмма BDI.4 по медиане", x = "BDI_4 (Больше медианы = 1)", y = "Количество") +
  theme_minimal()
```

## Применение критерия Мак-Немара и Кохрена для проверки значимости изменений в динакмике для первой и последней точки измерения:
```{r}
# Преобразование переменных BDI_1 и BDI_7 в дихотомические по медиане med1
data$BDI_1.binary <- ifelse(data$BDI_1 > med1, 1, 0)
data$BDI_7.binary <- ifelse(data$BDI_7 > med1, 1, 0)
# Выполнение теста Мак-Немара
mcnemar_test <- mcnemar.test(data$BDI_1.binary, data$BDI_7.binary)
print(mcnemar_test)
# тест Кохрена
library(DescTools)
cochran_test <- CochranQTest(cbind(data$BDI_1.binary, data$BDI_7.binary))
print(cochran_test)
```
Результаты теста McNemar's Chi-squared показывают следующее:

1. Значение статистики McNemar's chi-squared равно 150.01.
2. Число степеней свободы (df) составляет 1.
3. P-значение очень близко к нулю: "< 2.2e-16".

Интерпретация:
- P-значение близко к нулю, что говорит о том, что существует крайне малая вероятность получить такие или более экстремальные результаты случайно при условии верности нулевой гипотезы.
- Таким образом, мы отвергаем нулевую гипотезу о том, что нет изменений между двумя моментами времени (в данном случае между BDI_1 и BDI_7). Вероятно, наблюдается статистически значимая разница.
- Высокое значение статистики McNemar's chi-squared также подтверждает значимость изменений между этими двумя моментами времени.

Результаты теста Cochran's Q показывают следующее:

1. Значение статистики Q равно 152.
2. Число степеней свободы (df) составляет 1.
3. P-значение крайне мало и приближается к нулю: "< 2.2e-16".

Интерпретация:
- P-значение очень мало, что говорит о том, что существует крайне малая вероятность получить такие или более экстремальные результаты случайно при условии верности нулевой гипотезы.
- Таким образом, мы отвергаем нулевую гипотезу о том, что нет различий между группами.
- Вероятно, наблюдается статистически значимая разница между группами.

## Проверка однородности изменений во времени по критерию Стьюдента для зависимых выборок и по ранговому критерию Вилкоксона:
```{r}
t_test_results <- t.test(data$BDI_1, data$BDI_4, paired = TRUE)
print(t_test_results)
wilcox_test_results <- wilcox.test(data$BDI_1, data$BDI_4, paired = TRUE)
print(wilcox_test_results)
```
Результаты парного t-теста показывают следующее:

1. Значение статистики t равно 23.127.
2. Число степеней свободы (df) составляет 331.
3. P-значение крайне мало и приближается к нулю: "< 2.2e-16".

Интерпретация:
- P-значение крайне мало, что говорит о статистической значимости различий между BDI_1 и BDI_4.
- Мы отвергаем нулевую гипотезу о том, что различия между средними значениями BDI_1 и BDI_4 отсутствуют.
- 95% доверительный интервал для разницы между средними значениями лежит между 10.07392 и 11.94703.
- Средняя разница между BDI_1 и BDI_4 составляет 11.01047.

Результаты теста Wilcoxon signed rank показывают следующее:

1. Значение статистики V равно 52984.
2. P-значение крайне мало и приближается к нулю: "< 2.2e-16".
3. Альтернативная гипотеза указывает на то, что истинное смещение местоположения не равно 0.

Интерпретация:
- P-значение крайне мало, что говорит о статистической значимости различий между BDI_1 и BDI_4.
- Мы отвергаем нулевую гипотезу о том, что местоположение не изменилось (то есть, различия между BDI_1 и BDI_4 отсутствуют).
- Вывод: Существует статистически значимое смещение местоположения между BDI_1 и BDI_4.

## ANOVA Repeated Measures для зависимых переменных с факторами PROD.1, SEX.1. Проверка значимости факторов PROD.1, SEX.1, времени и эффекта взаимодействия:

Результаты анализа дисперсии (ANOVA) показывают следующее:

1. **ANOVA**:
   - Для фактора "Время" (Time) F-статистика равна 507.84, а p-значение близко к нулю (< 2.352389e-10). Это указывает на статистически значимое влияние времени на зависимую переменную.
   - Для взаимодействия между "Временем" и "Полом" (Time:SEX_1) F-статистика равна 7.00, а p-значение составляет 0.00995. Это также является статистически значимым.
   - Фактор "Пол" (SEX_1) не оказывает статистически значимого влияния на зависимую переменную (p = 0.086).
   - Значение eta-squared (ges) для всех факторов показывает, какой процент дисперсии объясняется каждым фактором. Например, фактор "Время" объясняет примерно 97.18% дисперсии.

2. **Тест Маухли на сферичность**:
   - Для фактора "Время" (Time) p-значение равно 0.2507554, что больше 0.05, что указывает на отсутствие нарушения сферичности.
   - Для взаимодействия между "Временем" и "Полом" (Time:SEX_1) p-значение также больше 0.05 (0.5171380), что указывает на сохранение сферичности.

3. **Коррекция сферичности**:
   - Для фактора "Время" (Time) и взаимодействия между "Временем" и "Полом" (Time:SEX_1) применяются коррекции сферичности (Greenhouse-Geisser и Huynh-Feldt), так как тест Маухли выявил нарушение сферичности.
   - p-значения после коррекции остаются статистически значимыми.

Интерпретация:
- Время (Time) и взаимодействие между временем и полом (Time:SEX_1) оказывают статистически значимое влияние на зависимую переменную.
- Фактор пола (SEX_1) не оказывает статистически значимого влияния на зависимую переменную при анализе совместного воздействия времени и пола.
- Наблюдается сферичность данных для всех факторов.

Эти результаты представляют анализ дисперсии (ANOVA) с дополнительными тестами на проверку сферичности (Маухли) и коррекцией сферичности.

1. **ANOVA**:
   - Фактор "Время" (Time) имеет высоко статистически значимое влияние на зависимую переменную (p < 2.352389e-10). Он объясняет около 97.18% дисперсии.
   - Фактор "Пол" (SEX_1) не достигает статистической значимости (p = 0.086).
   - Взаимодействие между "Временем" и "Полом" (Time:SEX_1) также статистически значимо (p = 9.948808e-03).

2. **Тест Маухли на сферичность**:
   - Для фактора "Время" (Time) и взаимодействия между "Временем" и "Полом" (Time:SEX_1) p-значения выше 0.05, что указывает на отсутствие нарушения сферичности.

3. **Коррекция сферичности**:
   - Применяются коррекции сферичности (Greenhouse-Geisser и Huynh-Feldt) для фактора "Время" (Time) и взаимодействия между "Временем" и "Полом" (Time:SEX_1), так как тест Маухли не выявил нарушения сферичности.
   - После коррекции сферичности, статистическая значимость остается высокой.

Вывод:
- Фактор "Время" (Time) и взаимодействие между "Временем" и "Полом" (Time:SEX_1) оказывают статистически значимое влияние на зависимую переменную.
- Фактор "Пол" (SEX_1) не оказывает статистически значимого влияния на зависимую переменную при учете взаимодействия с временем.
- Наблюдается сферичность данных для всех факторов после теста Маухли.